## Jingxuan Li  

### ü™∂ Academic Essays

**Du Ch√¢telet‚Äôs Critique and Reconstruction of Descartes‚Äô Theory of Knowledge**
(https://github.com/Jup1er/Philosophy/blob/main/academic/Du%20Cha%CC%82telet%E2%80%99s%20Critique%20and%20Reconstruction%20of%20Descartes%E2%80%99%20Theory%20of%20Knowledge.pdf)  
*This essay was written as a course assignment (PHIL 480) at McGill University (October 2025)*

This essay examines √âmilie du Ch√¢telet‚Äôs reinterpretation of Descartes‚Äô epistemology.  
It analyzes her criticism of the ‚Äúclarity and distinctness‚Äù criterion and shows how she replaces it with a demonstrable method grounded in logical principles ‚Äî the principle of contradiction, the principle of sufficient reason, and the law of continuity.  
Through this synthesis, du Ch√¢telet transforms Cartesian rationalism into a more rigorous and verifiable science of knowledge.

### üî≠ Future Research Interest

My interest begins with a deep curiosity about the relationship between large language models (LLMs) and human language.  
LLMs learn from human textual data, inheriting both the precision and ambiguity of human expression.  
As AI becomes increasingly integrated into daily life, people are exposed to more and more AI-generated text.  
When humans are shaped in turn by this language, we enter a loop where understanding itself becomes unstable.

#### Extended Directions

**1. Linguistic Vagueness and Cognitive Feedback**  
Language does not simply describe the world; it shapes how we perceive, reason, and exist.  
Many core concepts in both science and daily life, such as energy, force, probability, or luck, carry hidden ambiguities and metaphorical residues.  
These words are at once tools of explanation and sources of confusion.  
Science and ordinary language thus share a common vagueness that structures our understanding of reality.  
When large language models (LLMs) learn from such language, they do not merely reproduce knowledge; they amplify the uncertainty embedded in meaning, creating a semantic feedback loop between AI and humans.

**2. Risk Avoidance, Cognitive Outsourcing, and Human Education**  
From the perspectives of psychology and ethics, I would like to explore how reliance on AI affects human judgment.  
People may unconsciously delegate reasoning to machines, losing the capacity to learn through error or reflection.  
Understanding risks becoming a substituted act rather than a personal process of insight.  
This calls for a renewed notion of epistemic responsibility ‚Äî the ability to sustain independent, critical understanding in an age of technological mediation.  

---

*More essays and reflections will be added as my studies continue.*
